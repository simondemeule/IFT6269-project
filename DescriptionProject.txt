Multiple GANs have been proposed in recent years, trying to overcome problems existing in the original GAN paper such as Mode Collapse. We chose to work with the f-gan, a family of gan based on the f-divergences [1]. Our project will focus on both a theoritical analysis of the different divergences and how they influence the GAN objective, as well as a practical analysis of the various f-gans on different datasets (MNIST, ... ). Depending on the time it takes us to run initial experiments and analysis we would like to do further analysis with the model, for example a study of the prior-manifold mapping or attempting to put reinforcement learning in the model. 

[1]Nowozin, S., Cseke, B., & Tomioka, R. (2016). f-gan: Training generative neural samplers using variational divergence minimization. In Advances in neural information processing systems (pp. 271-279).
